---
layout: post
mathjax: true
title: Neural networks meet Projection pursuit and Latent variable regression
---
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" >
</script> 

Neural networks have been hitting the ball out of the park for a variety of machine learning problems in pattern recognition, computer vision, natural language processing and time series forecasting. In this article, I describe an application of neural nets to the classical regression problem, particularly when we have to deal with high dimensionality and nonlinearity at the same time. Of course, neural networks have been applied many times to such a setting, but here we will see an interesting (at least to me) approach that combines concepts from residual learning, projection pursuit and latent variable regression to give us an interpretable network architecture. It also gives us some nice by-products such as global sensitivities and a controllable low-dimensional projection of the input feature space that is chosen to best represent the influence on the dependent variable.

# The problem
Consider the standard regression problem, where we are given a sample set of $$s$$-dimensional vectors $$\mathbf{x}_i$$ from an $$s$$-dimensional input space and corresponding values $$y_i$$ of a dependent variable, and wish to generate a function $$\hat{y} = f(\mathbf{x})$$ such that the errors between $$\hat{y}_i = f(\mathbf{x}_i)$$ and $$y_i$$ are minimized in some sense.
Here we will minimize the sum of squared errors
$$
\sum_{i=0}^n (y_i - \hat{y}_i)^2.
$$

Apart from just obtaining some function $$f()$$ that minimizes this error, it is often desired to have $$f()$$ be interpretable in some way so as to reveal the structure of the relationship captured by it. One aspect of this structure that is often quite revealing is its true dimensionality. There may be $$s$$ (e.g. 10) dimensions in the input space, but it may be that the dependent variable is only significantly influenced by a small subset of those dimensions. This is what we typically refer to as predictor importance. A more interesting question is whether there is a lower dimensional projection of the input space that would largely explain the variation of the dependent variable.

![2D 1LV example]({{ site.baseurl }}/images/2var1lv.tif)

>>>2-D input space with 1 latent variable that explains all the variation in the dependent variable.
# The architecture

# By-products
## Global sensitivities
## Input-referred correlation
## Visualization

# Training

# References
